{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processamento dos dados\n",
    "\n",
    "**Autor:** Douglas Trajano\n",
    "\n",
    "Este notebook irá atuar no processamento dos dados para treinamento do modelo que irá predizer a variável `room_type`.\n",
    "\n",
    "As funções que irão fazer o processamento dos dados deverá estar em um arquivo **.py** com o objetivo de facilitar o deploy do modelo em um endpoint posteriormente.\n",
    "\n",
    "A estrutura completa do projeto pode ser vista [aqui](https://github.com/DougTrajano/ds_airbnb_rio)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>host_response_time</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>host_identity_verified</th>\n",
       "      <th>is_location_exact</th>\n",
       "      <th>property_type</th>\n",
       "      <th>room_type</th>\n",
       "      <th>accommodates</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>...</th>\n",
       "      <th>amenities_mountain_view</th>\n",
       "      <th>amenities_soaking_tub</th>\n",
       "      <th>amenities_beach_view</th>\n",
       "      <th>amenities_jetted_tub</th>\n",
       "      <th>amenities_sun_loungers</th>\n",
       "      <th>amenities_high-resolution_computer_monitor</th>\n",
       "      <th>amenities_private_pool</th>\n",
       "      <th>amenities_bidet</th>\n",
       "      <th>amenities_brick_oven</th>\n",
       "      <th>amenities_hbo_go</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   host_response_time  host_response_rate  host_is_superhost  \\\n",
       "0                 0.0               100.0                1.0   \n",
       "1                 1.0                91.0                0.0   \n",
       "2                 0.0               100.0                1.0   \n",
       "3                 0.0               100.0                1.0   \n",
       "4                 0.0               100.0                1.0   \n",
       "\n",
       "   host_listings_count  host_identity_verified  is_location_exact  \\\n",
       "0                  2.0                     1.0                  1   \n",
       "1                  3.0                     1.0                  1   \n",
       "2                  1.0                     1.0                  1   \n",
       "3                  1.0                     1.0                  1   \n",
       "4                  1.0                     1.0                  1   \n",
       "\n",
       "   property_type  room_type  accommodates  bathrooms  ...  \\\n",
       "0              0          0             5        1.0  ...   \n",
       "1              1          0             2        1.0  ...   \n",
       "2              1          0             3        1.0  ...   \n",
       "3              1          0             3        1.5  ...   \n",
       "4              2          0             2        1.0  ...   \n",
       "\n",
       "   amenities_mountain_view  amenities_soaking_tub  amenities_beach_view  \\\n",
       "0                      0.0                    0.0                   0.0   \n",
       "1                      0.0                    0.0                   0.0   \n",
       "2                      0.0                    0.0                   0.0   \n",
       "3                      0.0                    0.0                   0.0   \n",
       "4                      0.0                    0.0                   0.0   \n",
       "\n",
       "   amenities_jetted_tub  amenities_sun_loungers  \\\n",
       "0                   0.0                     0.0   \n",
       "1                   0.0                     0.0   \n",
       "2                   0.0                     0.0   \n",
       "3                   0.0                     0.0   \n",
       "4                   0.0                     0.0   \n",
       "\n",
       "   amenities_high-resolution_computer_monitor  amenities_private_pool  \\\n",
       "0                                         0.0                     0.0   \n",
       "1                                         0.0                     0.0   \n",
       "2                                         0.0                     0.0   \n",
       "3                                         0.0                     0.0   \n",
       "4                                         0.0                     0.0   \n",
       "\n",
       "   amenities_bidet  amenities_brick_oven  amenities_hbo_go  \n",
       "0              0.0                   0.0               0.0  \n",
       "1              0.0                   0.0               0.0  \n",
       "2              0.0                   0.0               0.0  \n",
       "3              0.0                   0.0               0.0  \n",
       "4              0.0                   0.0               0.0  \n",
       "\n",
       "[5 rows x 211 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/listings.csv\", low_memory=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / Divisão em X e Y, normalização dos dados\n",
    "\n",
    "Vamos dividir o dataset em duas partes: X e Y.\n",
    "\n",
    "`X` receberá todas as features, menos o `room_type`.\n",
    "`Y` receberá apenas o valor de `room_type`.\n",
    "\n",
    "Com base nas features `X` iremos inferir o valor de `Y`.\n",
    "\n",
    "Também iremos aplicar uma normalização dos dados com a técnica MinMaxScaler, isso facilita o algoritmo no entendimento dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (33715, 210)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(columns=[\"room_type\"])\n",
    "y = df[\"room_type\"].values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.values)\n",
    "\n",
    "print(\"X shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / Balanceamento das classes\n",
    "\n",
    "Como vimos anteriormente na análise exploratória, temos um desbalanceamento de classes que esperamos fornecer ao algoritmo.\n",
    "\n",
    "Isso pode gerar resultados inesperados, caso não seja endereçado da maneira correta, pois o algoritmo aprende também com o tamanho de exemplos que é fornecido para cada classe.\n",
    "\n",
    "Aqui utilizaremos uma técnica simples que é identificar os pesos para cada classe, isto será passado para o algoritmo que levará isso em consideração na hora de gerar o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.35197519522278364, 1: 0.964719011102209, 2: 11.788461538461538, 3: 26.673259493670887}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y), y=y)\n",
    "\n",
    "class_weights = {\n",
    "    0: class_weights[0],\n",
    "    1: class_weights[1],\n",
    "    2: class_weights[2],\n",
    "    3: class_weights[3]\n",
    "}\n",
    "\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## / Divisão do dataset em treino e teste\n",
    "\n",
    "Nesta etapa interemos dividir o dataset em mais duas partes: treino e teste.\n",
    "\n",
    "O objetivo é separar uma parte que será usada para avaliar o resultado do classificador e hyperparâmetros selecionados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 22589\n",
      "test size: 11126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset in train and test.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "print(\"train size:\", len(X_train))\n",
    "print(\"test size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# / modeling\n",
    "\n",
    "Agora que já temos o dataset pronto, vamos testar alguns modelos afim de encontrar o algoritmo que gera o melhor modelo para esse conjunto de dados, bem como seus hyperparâmetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### / Logistic Regression\n",
    "\n",
    "O primeiro algoritmo que iremos testar é a regressão logística.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (cross-validation): 0.88 (+/- 0.08)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9728    0.8876    0.9283      7910\n",
      "           1     0.8352    0.8861    0.8599      2872\n",
      "           2     0.6061    0.8967    0.7233       242\n",
      "           3     0.1706    0.8431    0.2838       102\n",
      "\n",
      "    accuracy                         0.8870     11126\n",
      "   macro avg     0.6462    0.8784    0.6988     11126\n",
      "weighted avg     0.9220    0.8870    0.9003     11126\n",
      "\n",
      "Wall time: 4min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000, random_state=0, class_weight=class_weights, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (cross-validation): %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### / Random Forest\n",
    "\n",
    "O segundo algoritmo que iremos testar é o RandomForest.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  6.9min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 640 out of 640 | elapsed: 26.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9869    0.9774    0.9821      7910\n",
      "           1     0.9443    0.9614    0.9527      2872\n",
      "           2     0.7891    0.9587    0.8657       242\n",
      "           3     0.8514    0.6176    0.7159       102\n",
      "\n",
      "    accuracy                         0.9695     11126\n",
      "   macro avg     0.8929    0.8788    0.8791     11126\n",
      "weighted avg     0.9703    0.9695    0.9695     11126\n",
      "\n",
      "Wall time: 26min 20s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0,\n",
       "                       class_weight={0: 0.35197519522278364,\n",
       "                                     1: 0.964719011102209,\n",
       "                                     2: 11.788461538461538,\n",
       "                                     3: 26.673259493670887},\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=5, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=300,\n",
       "                       n_jobs=-1, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# GridSearchCV\n",
    "parameters = {'n_estimators':[50, 100, 200, 300],\n",
    "             \"min_samples_leaf\": [5, 10, 15, 20],\n",
    "             \"min_samples_split\": [5, 10, 15, 20],\n",
    "             \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "model = RandomForestClassifier(random_state=0, class_weight=class_weights, n_jobs=-1)\n",
    "clf = GridSearchCV(model, parameters, cv=5, verbose=2, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "clf = clf.best_estimator_\n",
    "preds = clf.predict(X_test)\n",
    "print(classification_report(y_test, preds, digits=4))\n",
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (cross-validation): 0.97 (+/- 0.02)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9869    0.9774    0.9821      7910\n",
      "           1     0.9443    0.9614    0.9527      2872\n",
      "           2     0.7891    0.9587    0.8657       242\n",
      "           3     0.8514    0.6176    0.7159       102\n",
      "\n",
      "    accuracy                         0.9695     11126\n",
      "   macro avg     0.8929    0.8788    0.8791     11126\n",
      "weighted avg     0.9703    0.9695    0.9695     11126\n",
      "\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=300, criterion='gini', random_state=0, \n",
    "                             min_samples_leaf=5, min_samples_split=5,\n",
    "                             class_weight=class_weights, n_jobs=-1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv=5)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy (cross-validation): %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "print()\n",
    "print(classification_report(y_test, y_pred, digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model saved on model.sav'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def save_model(clf, filename=\"model.sav\"):\n",
    "    pickle.dump(clf, open(filename, 'wb'))\n",
    "    return \"Model saved on {}\".format(filename)\n",
    "\n",
    "def load_model(filename=\"model.sav\"):\n",
    "    clf = pickle.load(open(filename, 'rb'))\n",
    "    return clf\n",
    "\n",
    "save_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# / Conclusões\n",
    "\n",
    "Conseguimos obter uma boa acuracidade, porém, para que o modelo seja utilizado em produção é necessário obter mais exemplos para as classes `Shared room` e `Hotel room`. Essas classes juntas representam apenas **3%** do dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
